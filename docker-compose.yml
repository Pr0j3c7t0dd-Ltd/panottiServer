services:
  app:
    build: .
    ports:
      - "${API_PORT}:${API_PORT}"
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./.env:/app/.env
      - ./scripts:/app/scripts
      - ./ssl:/app/ssl
      - ./app/plugins:/app/app/plugins
      - whisper_models:/app/models/whisper
      - ./app:/app/app
      - ${RECORDINGS_DIR}:${RECORDINGS_DIR}
      - ./recordings:/app/recordings
    env_file:
      - .env
    environment:
      - PYTHONUNBUFFERED=1
      - WHISPER_MODEL_PATH=/app/models/whisper
      - POETRY_VIRTUALENVS_CREATE=false
      - DEBUG=1
      - SSL_CERT_FILE=/app/ssl/cert.pem
      - SSL_KEY_FILE=/app/ssl/key.pem
      - UVICORN_HOST=0.0.0.0
      - API_PORT=${API_PORT}
    depends_on:
      ollama:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-k", "-f", "https://127.0.0.1:${API_PORT}/docs"]
      interval: 30s
      timeout: 30s
      retries: 10
      start_period: 120s
    command: >
      sh -c "
      echo 'Waiting for Ollama to be healthy...' &&
      until curl -s http://ollama:11434/api/version > /dev/null; do
        echo 'Waiting for Ollama...' &&
        sleep 5;
      done &&
      echo 'Ollama is ready!' &&
      echo 'Pulling llama3.1:latest model...' &&
      curl -X POST http://ollama:11434/api/pull -d '{\"name\":\"llama3.1:latest\"}' &&
      echo 'Model pulled successfully!' &&
      echo '=== Environment ===' &&
      env | sort &&
      echo '=== Directory Structure ===' &&
      ls -laR /app &&
      echo '=== Starting App ===' &&
      /app/docker-entrypoint.sh
      "

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11435:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - GIN_MODE=release
      - OLLAMA_ORIGINS=*
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_COMPUTE=cpu
      - GOAMD64=v3
    dns:
      - 8.8.8.8
      - 8.8.4.4
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:11434/api/version || exit 0"]
      interval: 60s
      timeout: 60s
      retries: 15
      start_period: 180s
    restart: unless-stopped
    entrypoint: ["ollama"]
    command: ["serve"]

volumes:
  ollama_data:
  whisper_models: 